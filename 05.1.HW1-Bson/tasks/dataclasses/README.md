
## Библиотека для формата BSON

### Введение

Важной задачей в промышленной разработке является сериализация и десериализация данных - перевод в формат,
отделенный от контекста исполнения. Это может быть сохранение на диске с целью последующего прочтения. Или пересылка
данных другому процессу.

Название происходит от того, что нелинейно (как минимум - иерархически) структурированные данные превращаются в последовательность
байтов и обратно. В английском языке для этих двух операций также часто используются названия `marshal` и `unmarshal`.

`protobuf`, `json`, `xml`, `avro`, `pickle` - это лишь некоторые из известных подходов. В каждом из них есть свои плюсы
и свои минусы.

В этом задании мы разработаем библиотеку для сериализации/десериализации с использованием формата [BSON](https://bsonspec.org).

Это бинарная вариация на тему более известного формата `JSON`.

`BSON` используется как формат для общения клиентов с `MongoDB`. И в его спецификации есть явные следы этого варианта использования -
это видно по типам полей.

Но его можно приспособить и для передачи данных в других целях, чем мы и займемся. Поэтому как таковая `MongoDB` для работы над заданием не нужна.
Но может быть полезной утилита `bsondump`, которая создана разработчиками `MongoDB` и которая распространяется как отдельный артефакт.

С ее помощью вы можете проверять, что ваш код действительно порождает то, что нужно.


### Общая схема сдачи

Вся работа состоит из набора инкрементальных заданий.

Каждое последующее - это шаг вперед на основе предыдущего. И набор тестов нарастает от задания к заданию. Чтобы отдельное задание
было зачтено, его тестовый набор должен быть пройден полностью.


### Задание 1

Базовая сериализация и десериализация.

В этом задании мы поддерживаем передачу данных из Python-приложения в Python-приложение.
И рассчитываем на то, что пользоваться нашей библиотекой будут аккуратно и корректно.

При сериализации на вход будут поступать только корректные и поддерживаемые структуры,
не будет никаких списков, явяляющихся элементами самих себя и т.п..

А при десериализации на вход придет только то, что является порождением корректной сериализации.

Реализуем модуль `bson`, в интерфейсе которого будут две функции:

- `marshal(data)` - принимающая словарь, подлежащий сериализации и возвращающая объект типа `bytes`

- `unmarshal(data)` - принимающая объект с интерфейсом объекта типа `bytes` и возвращающая десериализованный
словарь.

#### Простейшая сериализация

Самое простое, что можно передать функции `marshal` - это пустой словарь.

В терминах bson-спецификации это будет документом и такой простейший документ превратится в 5 - согласно (правилам)
[https://bsonspec.org/spec.html].

Сначала сработает правило:

```
document	::=	int32 e_list unsigned_byte(0)
```

а потом - вторая ветка правила

```
e_list	::=  element e_list	
             | ""
```

Правила мы читаем так:

- `document` - это `int32`, потом `e_list`, потом `unsigned_byte(0)`
- `int32` и `unsigned_byte(0)` - это базовые сущности
- `e_list` - это список элементов, возможно, что пустой (и в нашем случае так и есть)

В итоге получится такой набор байтов: `[5 0 0 0 0]`

#### Что-то более содержательное 

Давайте сериализуем словарь `{'name': 'vasya'}`. 

Здесь вступает в действие одно из правил для `element`:

```
element	::= signed_byte(2) e_name string 

e_name ::= cstring
string ::= int32 (byte*) unsigned_byte(0)
cstring	::= (byte*) unsigned_byte(0)
```

Обращаем внимание на детали. Имя элемента и его содержимое - это строки, но разные. У одной явно
указана длина, у другой нет. Это НЕ означает, что длина значения как-то более существенно ограничена,
чем длина ключа. Потому что размер документа - тоже `int32`. Но это означает, что в значении можно использовать
нулевой байт, а в ключе - нельзя.

Вне зависимости от того, почему оно так, нам следует придерживаться правил выбранного формата.

И надо не забыть про то, что длина документа поменялась.


#### Числовые типы

Вещественные мы хотим хранить в их бинарном представлении в элементе соответствующего типа (1).

Для целых есть два типа элемента - 32-битный (16) и 64-битный (18). Если число влезает в 32-бита,
будем использовать 32-битный, если нет - 64-битный (пока предполагаем, что в 64-битный числр точно влезет).


#### Логические и None 

У логического есть свои тип элемента (8). При десериализации пока будем считать, что там может быть только 0 или 1.

None соответствует тип элемента Null value (10).


#### `datetime`

В BSON есть отдельный тип элемента `UTC datatime` (9). В нем мы хотим сериализовать значения класса
`datatime` с указанным `tzinfo` в виде количества милисекунд с `00:00:00.000` 1 января 1970 года в зоне `UTC`.

Тут появляется ассиметрия. Мы храним только число милисекунд, но не храним саму исходную таймзону. Поэтому при десериализации
у нас всегда получится время в таймзоне `UTC`.


#### Байтовые наборы 

В BSON есть отдельный тип элемента `Binary data` (5). Он имеет свою внутреннюю структуру с многими подтипами.

Будем хранить в нем содержимое Python-объектов типа `bytes` и `bytearray`.

Будем использовать подтип `Generic binary subtype` (0).

И здесь тоже ассиметрия - мы не храним знание о исходном типе. Давайте произвольно примем решение о том, что при все
десериализуется в `bytes`.


#### Документы как значения

Было бы очень странно, если бы схема сериализации не поддерживала иерархичность. 

Тип элемента `Embedded document` (3) - именно про это. В нем мы будем хранить рекурсивно сериализованный
вложенный словарь.

И здесь мы так же считаем, что все с входными данными будет хорошо. Например, все ключи всех словарей на любых уровнях вложенности
будут строками.

Про глубину вложенности предполагаем, что она может быть ограниченно произвольной. Вложенное  во вложенное
вполне ожидаемо, а вот вложенность на 350 уровней - вряд ли.

И раз уж мы говорим о документах в целом - договоримся о порядке сериализации ключей. BSON не дает на этом счет никаких указаний.
Но нам хотелось бы определенности. Как минимум для того, чтобы два словаря с одинаковым набором пар ключ/значение гарантированно
порождали один и тот же бинарный образ.

Давайте порождать элементы каждого документа в лексикографическом порядке ("по алфавиту") его ключей.

Тут появляется другого рода ассиметрия. На этот раз можно взять бинарный образ, десериализовать его, потом снова сериализовать -
и получить в итоге другой бинарный образ, не совпадающий с оригиналом.


#### Списки и кортежи

И задействуем еще один тип элемента - `Array` (4).

В нем будем хранить списки и кортежи. При десериализации будем порождать списки.

Это может показаться не очень логичным. Ведь для набора байтов мы порождаем `bytes` - неизменяемый тип.

Обоснование такое - `bytes` действительно логичен именно тем, что он неизменяем. И по этой логике хорошо
бы и `Array` десериализовывать в кортежи. Но в Python-сообществе не прижилась идея использовать кортеж для
длинных наборов однородных элементов. А `Array` в BSON - это скорее именно про такой случаях. Небольшое число
разнородных - формально возможный вариант, но в BSON для этого все-таки больше подходит документ.

Заметим, что на бинарном уровне `Array` хранится фактически как документ с ключами '0', '1', `...`. И мы, конечно же,
в этот момент подумаем, а не переиспользовать ли здесь логику работы со словарями.

Конечно же, можно, но давайте не будем лексикографически упорядочивать ключи. Пусть они идут по возрастанию именно в числовой интерпретации.

### Задание 2

Базовая обработка ошибок

В первом задании мы сфокусировались на основной логике. Но в продакшен-коде этого мало. Нужна надежная
и продуманная обработка разных вариантов неожиданных входных данных.

Не всегда схожу очевидно, как же их обрабатывать. То есть как обрабатывать - вроде бы понятно. Бросать исключения.
Но всегда ли стоит это делать - это еще вопрос.

Понятно, что если мы пытаемся десериализовать набор байтов и он обрывается посреди какого-то значения - это явная проблема.

Но по ряду пуктов могут быть вопросы. Считать ли ошибкой сериализации нестроковый ключ в словаре или просто молча его пропустить ?

Или считать ли ошибкой десериализации встреченный тип элемента, который мы не поддерживаем при сериализации ?

На последний вопрос можно отвечать по-разному в зависимости от наших целей. Ожидаем ли мы прочитать именно сериализованный нами документ
или готовы принимать данные, порожденные кем-то еще ? В первом случае мы скорее увидим в таком неожиданном элементе признак того,
что нам на вход пришло что-то не то. А во втором скорее захотим обработать знакомые нам поля, молча проигнорировав незнакомые.

В этом задании мы реализуем базовую стратегию, которая будет работать по умолчанию.

Прежде, чем ее описать, опишем нашу иерархию исключений:

```
BsonError
- BsonMarshalError
-- BsonUnsupportedObjectError
-- BsonUnsupportedKeyError
--- BsonKeyWithZeroByteError
-- BsonInputTooBigError
--- BsonBinaryTooBigError
--- BsonIntegerTooBigError
--- BsonStringTooBigError
--- BsonDocumentTooBigError
-- BsonCycleDetectedError
- BsonUnmarshalError
-- BsonBrokenDataError
--- BsonIncorrectSizeError
--- BsonTooManyDataError
--- BsonNotEnoughDataError
--- BsonInvalidElementTypeError
--- BsonInvalidStringError
--- BsonStringSizeError
--- BsonInconsistentStringSizeError
--- BsonBadStringDataError
--- BsonBadKeyDataError
--- BsonRepeatedKeyDataError
--- BsonBadArrayIndexError
--- BsonInvalidBinarySubtypeError
```

#### Проверки при сериализации

Принципы проверки при сериализации:

- если на входе не словарь, то это `BsonUnsupportedObjectError`

- если попадается подлежащее сериализации значение неподдерживаемого типа, то это `BsonUnsupportedObjectError`

- если попадается подлежащий сериализации словарь с хотя бы одним нестроковым ключом, то это `BsonUnsupportedKeyError`

- если попадается подлежащий сериализации словарь со строковым ключом, содержащим хотя бы один нулевой байт в `UTF-8`,
то это `BsonKeyWithZeroByteError`

- если попадается целое число вне диапазона значений знакового 64-битового целого, то это `BsonIntegerTooBigError`

- если попадается подлежащая сериализации строка, переполняющая вместимость типа элемента `UTF-8 string`, то это `BsonStringTooBigError`

- если попадается подлежащий сериализации байтовый тип, переполняющий вместимость типа элемента `Binary data`, то это `BsonBinaryTooBigError`

- если в ходе сериализации переполняется вместимость типа элемента `BSON Document`, то это `BsonDocumentTooBigError`

- если попадается подлежащее сериализации значение, сериализацией которого мы сейчас уже занимаемся, то это `BsonCycleDetectedError`
-- 

При обработке каждого из документов сначала проверяются основания для `BsonUnsupportedKeyError` (в строгом смысле),
для `BsonKeyWithZeroByteError` и для `BsonUnsupportedObjectError` непосредственно в этом документе (без рекурсии) - именно в таком порядке.

Если во входном документе есть циклическая вложенность, то чисто технически ее можно игнорировать и упасть по `BsonDocumentTooBigError`.
Но мы так не хотим. Если есть циклическая зависимость, обнаруживаемая до того, как появились основания для `BsonInputTooBigError`,
то важно бросить именно `BsonCycleDetectedError`.

Проверка оснований для `BsonInputTooBigError` и наследников производится после завершения обработки каждой пары ключ-значение.
Например, если в документе очень-очень много пар ключ-значение, пусть и умеренной длины каждое, мы можем переполнить документ, не
успев обработать все ключи. И об этом надо сообщить именно после обрабтки той пары, которая все переполнила и не обрабатывать все, что
идет дальше.

Если появились основания для какого либо из `BsonInputTooBigError` и одновременно для `BsonDocumentTooBigError` применительно к одному
из объемлющих документов, то должно быть брошено исключение, касающееся элемента, а не объемлющего документа.

А про проверки во время десериализации будет следующее задание.


### Задание 3

#### Проверки при десериализации 

При десериализации документа в первую очередь проверяется наличие 4 байтов для хранения размера.

Если их нет - это `BsonBrokenDataError`.

Если они есть, то проверяется

- не меньше ли он минимально возможного в принципе. Если меньше - это `BsonIncorrectSizeError`

- равен ли он размеру поданных данных. Если меньше - это `BsonTooManyDataError`, если больше - это `BsonNotEnoughDataError`.

После этого идет обработка элементов входного документа.

Если любой из ключей не декодируется по правилам `UTF-8`, то это `BsonBadKeyDataError`.

Если любой из ключей словаря повторяется, то это `BsonRepeatedKeyDataError`

Если встретился тип элемента, не описанный в спецификации BSON, то это `BsonInvalidElementTypeError`.

Если встретился тип элемента, описанный в спецификации BSON, но тот, которые не порождается нами при сериализации, то мы его читаем
на общих основаниях, но никак не сохраняем.

Но мы должны проверить даже неподдерживаемый тип на корректность внутренней структуры. Например `JavaScript code with scope`
должен иметь в своем составе `document`, а `binary` - корректный `subtype`. В последнем случае должен бросаться
`BsonInvalidBinarySubtypeError`.

После чтения каждой пары ключ-значение, проверяем, не вышли ли мы за размер любого из объемлющих документов. Если вышли - это
`BsonBrokenDataError`.

Если в ходе десериализации значения типа элемента `UTF-8 string` выясняется, что заявленный размер строкового значения заведомо
некорректен, то это `BsonStringSizeError`. Аналогично с любым применением `string`.

Если этот размер вылезает за размер любого из объемлющих документов - это `BsonInconsistentStringSizeError`.

Если строка не декодируется по правилам `UTF-8`, то это `BsonBadStringDataError`.

Если после заявленного размера строки нет нулевого байта, то это `BsonBrokenDataError`.

Если после заявленного размера документа нет нулевого байта, то это `BsonBrokenDataError`.

При обработке типа элемента `Array`, помимо общих уже описанных проверок, мы также ждем, что там не будет нечисловых индексов.

А "дырки" в нумерации могут быть. Посколько общая идея в том, что принимаем документы, которые мог породить кто-то кроме нас,
то мы готовы к разным вариантам. Скорее всего такая организация `Array` пришла в `BSON` под влиянием `JavaScript`,
в котором могут быть такие дырки в индексах. То есть мы при десериализации должны вернуть массив, заполнив дырки None-ами.

Если же в массиве были нечисловые индексы, то это `BsonBadArrayIndexError`.


### Задание 4

Классовое API

Дальше мы хотим поиграть с разными настройками сериализации и десериализации.

Настраивать логику через параметры функций неудобно. Во-первых потому что параметров много.
Во-вторых, потому что часто нам в разных контекстах удобно разные конфигурации параметров считать
естественными и брать их в качестве умолчания.

Это значит, что нам нужно перейти к API в стиле ООП, хранить настройки в состоянии объекта и вызывать
основную логику через методы.

Назовем такой класс `Mapper` и пусть у него будут методы `marshal` и `unmarshal`.

Даже в таком нехитром классе есть место для применения особенностей ООП именно в Python-стиле.

Не хотелось бы фиксировать в API класса список парамеров конфигурации. Пусть конструктор принимает произвольное
число параметров, которые должны быть в обязательном порядке именованными.

Если передается параметр, не соответствующий поддерживаемой опции - должно быть брошено исключение `MapperUnsupportedOptionError`.

Если же передается, то оно перекрывает значение этого параметра по умолчанию. И далее оно доступно как свойство,
то есть без вызова метода, а все попытки его изменить или удалить должны порождать исключение.

То есть если вызвать конструктор совсем без параметров, то семантика вызываемых далее методов должна
быть точно эквивалентна вызовам функций.

Более того, нам вовсе НЕ нужно убирать из API модуля функции. Их логика должна переехать в методы класса, а в теле каждой из
функций должен появиться вызов соответствующего метода над объектом, созданным со значениями параметров по умолчанию.

Также в рамках этого задания поддержим первую опцию конфигурирования десериализации - `python_only`.

Смысл этой опции - в том, чтобы усилить проверки и принимать только те входы, которые могли быть порождены нашим же сериализатором.

Исключение сделаем только для двух случаев:

- ненулевое и неединичное значение логического типа будет воспринимать спокойно и превращать в `True`.

- значение элемента типа `int64`, укладывающееся в диапазон `int32`, тоже будем воспринимать спокойно.

В случае обнаружения типа элемента, который не мог быть порожден нашим кодом, в таком режиме должно быть брошено
исключение `BsonInvalidElementTypeError`.

Итак, по итогам этого задания должен появиться класс Mapper со следующими сценариями:

```
m = Mapper()
print(m.python_only) # False
```

```
m = Mapper()
m.python_only = True # порождает AttributeError
``` 

```
m = Mapper()
del m.python_only # порождает AttributeError 
``` 

```
m = Mapper(something=True) # порождает MapperConfigError
``` 

```
m = Mapper(True) # порождает исключение
``` 


```
m = Mapper(python_only=True)
print(m.python_only) # True 
``` 

```
m = Mapper(python_only=False)
print(m.python_only) # False 
``` 

На поведение сериализации флаг `python_only` не влияет.

Что касается десериализации:

- при значении False метод `unmarshal` ведет себя иак же, как и функция

- при значении True метод `unmarshal` начинает бросать дополнительные исключения, согласно описанию.

Также этот флаг влияет на интерпретацию бинарных полей и индексов в массиве.

При включенном `python_only` режиме считаем поводом к исключению любой бинарный подтип, кроме нулевого.

А для массивов заведем новое исключение - `BsonInvalidArrayError` - на тот случай, если режим `python_only`
был включен и мы обнаружили массив с "дырками" в индекcах.


### Задание 5

Добавим в класс `Mapper` еще один конфигурационный флаг: `keep_types`.

Смысл его состоит в следующем: мы хотим порождать (или не порождать - в зависимости от значения флага)
какое-то знание о том, из каких типов данных было порождено содержимое документа. Чтобы при восстановлении
знать, создавать ли на список или кортеж, `bytes` или `bytearray`.

Будем хранить это знание на уровне сериалируемого документа.

Заведем специальное поле с именем `__metadata__` типа `binary` с пользовательским подтипом `128`.

И для документа будем там хранить разделенную двоеточиями строку, точнее - ее представление в `UTF-8`.

Например, для документа с ключами `abc` и `bcde` это могла бы быть строка `tuple:bytes` и она бы означала, что
в по ключу `abc` хранится кортеж, а по ключу `bcde` - bytes.

Если для какого-то поля и так все понятно, в соответствующей позиции должна быть пустая строка. Например, если
бы по ключу `bcde` хранилось вещественное число, то в метаданных надо было бы хранить строку `tuple:`. А если бы по ключу
`abc` хранился список - то строку `:`. Поточу что список и так используется по умолчанию.

Если при сериализации в маппере включен режим `keep_types`, то мы порождаем такого рода информацию для ключей документов.

Если при десериализации в маппере включен режим `keep_types`, то мы используем такого рода информацию для ключей документов.

Порядок описаний полей соответствует порядку хранения ключей. То есть лексикографический для классических документов и
по порядку индексов для документов, хранящих массив. Почему так для массивов ? Как минимум потому что когда смотришь на дамп,
текстовые метаданные неплохо прочитываются и если это данные о массиве, хочется примерно понимать из них что по какому индексу.
А это проще понимается при хранении по порядку индексов. В то же время, эта тема с метаданными - это внутрипитоновская тема
и она никогда не возникнет в сочетании с дырками в индексации.

Корректируем поведение флага `python_only`, чтобы бинарное поле с именем `__metadata__` и подтипом `128` считать валидным
и даже при отключенном флаге `keep_types` не считать его наличие поводом для ошибки при десериализации.

А что, если в сериализуемом документе уже есть ключ с таким именем и нам еще нужно его завести в своих целях ? 
Будем хранить оба ключа, различать их будем по типу и бинарному подтипу и не считать такое совпадение имен ключей поводом
к бросанию исключения.


### Задание 6

У нас пока довольно бедно представлены типы "словарного плана".

Есть кортежи и списки, есть `bytes` и `bytearray`. И только словарь.

Даввайте добавим поддержку для именованных кортежей, дата-классов и объектов
со свойствами (property).

В логике сериализации добавим проверки, а не именованный ли это кортеж.

Если да - сериализуем как документ.

Если нет - проверим, а не экземпляр ли это датакласса.

Если да - сериализуем как документ.

Если нет - проверим, а нет ли читаемых свойств.

Если есть хотя бы одно сериализуем как документ.

Это "хотя бы одно" пусть относится только к свойствам.
Для именованных кортежей можно и экземпляров датаклассов будет даже
тех, кто без полей сериализовывать.

Именованный кортеж можно проверить по характерным атрибутам класса и по `tuple` в роли базового класса.
Спискок полей тоже можно взять из атрибутов класса.

Датакласы можно определить по непустому атрибуту `__annotations__`, а ключи этого словаря можно тоже считать за
список полей. Только давайте при сериализации смотреть на эти ключи как на поля и через них добывать данные.
А с типом разбираться по реальным данным.

Проперти тоже пребывают в роли атрибутов класса. И эти атрибуты тоже имеют вполне отличимый тип.

Здесь мы пока не поддерживаем для этих типов режим `keep_types`. То есть при десериализации они все превратятся в словари.

Возможные проблемы давайте решать так. Если какая-то `property` не читается - просто молча ее пропускаем. Если не нашли ни одной - считаем
документ несериализуемым. Ведем себя с ним как и с любым другим несериализуемым объектом.

Именованные кортежи и экземпляры датаклассов считаем за сериализуемые сущности, но если значение атрибута не сериализуется, то и владеющий
им объект - тоже.

И с порядком полей придерживаемся общих принципов: однозначности порождения и удобства/естественности прочтения человеком.

В случае именованных кортежей будем хранить поля в порядке их упоминания в `_fields`.

В случае дата-классов будет хранить поля в порядке их упоминания в `__dataclass_fields__`.

А если это объект, в котором обнаружены `property`, то хранит ключи в лексикографическом порядке.


### Задание 7

Давайте поддержим `keep_types` для именованных кортежей.

Тут все не так просто.

Первая проблема - а откуда нам взять класс для восстанавливаемого именованного кортежа ?

В принципе, мы эту информацию можем передать. Мы можем узнать, какие у класса есть поля
и даже какие значения по умолчанию.

Но мы не хотим для каждого объекта передавать эту информацию. И тем более не хотим на принимающей
стороне на каждый объект создавать новый класс.

Эту проблему решим так. При сериализации будем фиксировать встречающиеся классы именованных
кортежей. Как только находим новый (в естественном порядке просмотра элементов данных), даем ему
строковый идентификатор. Первому найденному - `nt-0`, следующему - `nt-1` и так далее.

В тех местах, где используется поле данного типв, добавим маркер типа поля, равный данному идентификатору.
Ровна так же, как мы делали для `tuple` и `bytearray`.

И на надо куда-то положить данные о типах с этими идентификаторами. Данных может быть довольно много.
Достаточно много для того, чтобы не придумывать какие-то форматы на коленках, а использовать уже знакомый.

Мы можем сохранить данные в виде словаря, в котором ключами будут наши строковые идентификаторы типов, а
значениями - тоже словари. С тремя ключами. По ключу `name` будем хранить имя класса. По ключу `fields` - список
имен полей. А по ключу `defaults` - тоже словарь. В нем ключи - имена полей, а значения - значения по умолчанию.

Этот словарь мы можем тоже сериализовать. И хранить в бинарном поле с пользовательским подтипом.

И мы хотим вести себя максимально скромно. Не занимать лишних ключей и подтипов. Вот есть у нас ключ `__metadata__`
и подтип 128. И давайте умещаться в нем.

Положить туда сериализованный словарь - несложно. Но как быть с уже имеющимимися значениями, которые мы реализовывали в
задании 6 ?

Сразу скажем, что такая проблема есть только в корневом документе. Потому что вот этот вот словарь типов - он сохраняется
только один раз и только в корне.

И отказываться от старого формата мы не хотим там, где в этом нет необходимости. Ее даже в корневом документе может не быть.
Например, если у нас было именованных кортежей нигде. Не хотим - потому что он такой простой и человекочитаемый.

Давайте сделаем так. Если в корневом документе есть необходимость хранить метаданные из прошлого задания и также есть необходимость
хранить словарь типов, давайте старые метаданные тоже хранить в словаре.

Заведем в словаре еще один уровень. В нем будет ключ `types` - и данные о типах в уже описанном формате.
И поле `children` - с данными о типах элементов корневого документа в уже известном формате.

И этот уровень пусть будет всегда. Даже если у нас только данные о типах.

Если мы в корневой документ добавляем такой сериализованный словарь, то перед ним допишем нулевой байтик.

Тогда при десериализации мы поймем, лежит ли тут сериализованные словарь или данные в старом упрощеном формате.
Коллизий тут не будет.

Тут еще есть пара проблем. Одну из них я только обозначу, а другую мы еще и решим.

Связываясь со значениями по умолчанию, мы открываем ящик Пандоры. Там же может быть примерно что угодно.
И циклические типы, и произвользольная вложенность. И если там есть кортежы, то нам придется еще и рекурсивные метаданные
создавать. Да, проблема есть. И решать ее будет оверкил в рамках домашки. Но с другой стороны - перетащить типы на другую машинку
может быть полезным. Поэтому сделаем в предположении, что данные хорошие. Чиселки, строчки.

А другая проблема - в том, где хранить данные о типе документа. Мы вроде уже решили хранить их в объемлющем документе для кортежей
и байтовых массивов. Но у корневого документа нет объемлющего. И что нам делать, если мы сериализуем именованный кортеж в виде
корневого документа ?

И сказать, что давайте хранить такие данные в самом документе, а не в объемлющем - тоже не выходит. Это было бы здрово и
не надо было бы вот эти конструкции с двоеточиями создавать. Но эта идея ломается на `bytearray`. У него нет своего документа.
В отличие от кортежа. И не получается сказать, что это какой-то маргинальный тип. Ну не будет `bytearray` - мы захотим хранить данные о
таймзоне для `datetime`, например.

Решим эту проблему так. Если у нас корневой документ порождается из именованного кортежа - добавим для него ключ в сериализуемый
словарь метаданный. Пусть это будет ключ `self` и в качестве значения там хранится строковый идентификатор типа.



### Задание 8

Здесь мы пойдем уже проторенным путем и поддержим `keep_types` для датаклассов.

Принципиальные проблемы уже решены в задании 7.

Здесь точно так же храним данные о типах в словаре типов. Только для датаклассов будет префикс
`dc-`. Нумерация пусть будет общая для всех типов.

Тоже будет словарик с метаданными. Что будем хранить:

- имя по ключу `name`

- данные об аннотациях по ключу `annotations`

- данные о параметрах декоратора по ключу `params`

Если сравнивать с именованными кортежами, то имена полей поедут как часть данных об аннотациях.

Значения по умолчанию здесь реализовывать не будет. Но можно было бы. Надо было бы просто проверить атрибуты класса
с именами, равными именам полей. И собрать их значения, а при десериализации установить в атрибуты созданного класса.

Данные об аннотациях несложно найти среди атрибутов класса. Нам интересны имена полей. Они должны стать ключами
в словаре, который будет храниться по ключу `annotations`. А значениями в нем должны стать строковые представления
аннотаций.

Не будет аккуратно поддерживать все случаи. Для аннотации `str` давайте хранить строку "str", для `int` - строку "int",
для `bool` - "bool". Для всех остальных - `any`.

При сериализации восстановим аннотации по этому знанию.

Данные о ключах декоратора - словарь с ключами 
`init`, `'repr`, `eq`, `order`, `unsafe_hash`, `frozen`.
Это как мы их храним при передаче. А узнать их значения для типа в момент сериализации
можно из атрибутов класса.

При сериализации надо создать класс с заданным именем, добавить в него аннотаций и применить
декоратор с нужными параметрами.

